Nous avons vu que les KGs apportent à la donnée un contexte sémantique nécessaire à une compréhension plus approfondie du fait, permettant la construction d'argumentaires plus élaborés. Cet argumentaire se base sur les chemins qui lient le sujet et l'objet du fait. Des approches complexes vont permettre d'obtenir des informations pertinentes sur les faits. Seulement les approches étudiées ne permettent pas d'aboutir à un système de fact checking efficace et rapide, qui permet une montée en charge importante des données. De plus cette approche est limitée aux faits de la forme d'un triple.

Ensuite, nous avons vu des approches qui s'orientent sur la récupération et l'analyse de données brutes sur le web. Par exemple si l'on considérait ClaimBuster et Credeye comme un système unique, ce système permettrait :
\begin{itemize}
    \item la récupération automatique de sources d'informations (ClaimBuster)
    \item l'identification de faits vérifiables (ClaimBuster)
    \item la recherche d'un argumentaire sur le web (ClaimBuster et Credeye)
    \item une approche plus ou moins fiable de TALN pour la compréhension des données et des sources (ClaimBuster et Credeye)
\end{itemize}
Ce système serait capable d'effectuer toutes les étapes de fact-checking d'une fake news. Mais plusieurs problèmes se posent, le TALN n'est pas parfait et les sources du web ne sont pas fiables. 

Le but de cet exposé sur ClaimBuster était de montrer les challenges liés au fact-checking, et avoir un aperçu global des étapes nécessaires qu'un système de fact-checking doit pouvoir prendre en charge. Mais ClaimBuster a aussi permis de montrer le rôle et le fonctionnement du machine learning. Nous avons vu qu'il était peut être mal utilisé dans le cas de ClaimBuster, ou du moins que d'autres solutions étaient possibles.

De leur côté, les KGs ont permis d'avoir un aperçu du web sémantique et de son potentiel : des bases de données géantes et interopérables qui traitent de l'information complexe. Ils permettent d'effectuer des opérations de fact-checking simples mais offrent des capacités d'évolution et un contexte sémantique important.
\\*
Mais les KGs disposent de trop peu d'informations et celle-ci est souvent très générique.

Comment serait-il possible de combiner les avantages de ces deux approches ? Est-il possible de construire un algorithme de type machine learning qui s'entraînera sur des données complexes issues de bases de connaissances ? Le but serait de rassembler sur un même support les données complexes des KGs permettant de définir un contexte sémantique avec la capacité d'apprentissage du machine learning. Cela permettrait de palier au manque d'information, à la fiabilité de l'information et au manque de scalabilité des KGs. En effet, on a donc d'un côté des approches comme ClaimBuster qui peuvent faire du fact-checking (partiel) en live mais manquent de précision et ont un champ d'action restreint dû à des données trop disparates. Et d'un autre côté on a avec les KGs des données complexes mais un temps de réaction trop long pour faire du fact-checking en live.

D'autre part, ClaimBuster utilise des techniques qui ne trouvent pas forcément leur utilité dans une approche par les KGs. Par exemple sa plus grande force est sa capacité à détecter des faits vérifiables. Dans le cas d'un KG, tout fait sous forme de triple est vérifiable.

Pour associer ces deux approches il faut aussi prendre en compte le fait qu'un système de fact-checking doit avoir accès à des données récentes. L'idéal serait une base de connaissance qui permettent de récupérer les informations sur le web en temps réel et puissent assurer la validité de l'information (voir couches Trust et Proof du web sémantique). D'autre part il faudrait pouvoir utiliser cette base pour évaluer des assertions et obtenir des résultats dans un temps raisonnable.

Nous verrons tout d'abord la base Knowledge Vault qui aspire à devenir la base de connaissance décrite précédemment \cite{dong2014knowledge}. Puis nous verrons si le machine learning appliqué aux KGs est possible, dans quelles mesures, et s'il est une réponse viable aux problèmes posés par le fact-checking.

\subsection{Knowledge Vault}

Knowledge vault (KV) est une base de connaissance développée par Google. Elle s'inscrit dans la suite du Google Knowledge Graph et tente de l'étendre vers des sources d'information bien plus conséquentes. En effet KV a pour but de créer une base de connaissance à l'échelle du web \cite{dong2014knowledge}. Le problème des bases de connaissance est qu'elles reposent sur une action humaine pour être maintenues et enrichies. Leur évolution est lente et l'intégration de contenus récents fait défaut. De plus l'approche humaine est trop chronophage pour produire du contenu spécifique fiable et en quantité. Pour répondre à ce problème, il faut automatiser les processus nécessaires à la construction d'une base de connaissance. La mise en oeuvre est complexe. La première étape serait de requêter les sources du web. Ensuite il faut traiter et formater l'information sous forme de triple pour enfin enrichir la base.

Seulement cette approche revient à requêter les sources du web et appliquer du TALN ou du machine learning. Avec cette vision, on hérite des problèmes liés à l'incertitude de la donnée sur le web et à son traitement. Il est nécessaire de rendre la donnée fiable et structurée.

Comme nous l'avons précisé, les bases de connaissances peuvent déduire de l'information en se basant sur des ontologies. Si l'on récupère un fait qui nous dit que Barack Obama est né au Kenya, nous allons utiliser des faits antérieurs et connu pour vérifier cette affirmation. Sachant que Barack Obama est président des États Unis, cette affirmation a beaucoup de chance d'être fausse. KV va pousser cette capacité à déduire de l'information à l'extrême pour à la fois construire du savoir mais aussi pour valider de nouvelles connaissances.
\\*
Pour combattre l'incertitude des sources de données disponibles sur le web il est nécessaire de dériver de la connaissance à partir des bases existantes. KV se construit autour de bases existantes (notamment Freebase et le Google Knowledge Graph) pour assurer la fiabilité des nouvelles données qu'il amasse. Il se base sur les 1,6 milliard de triplets dont il est composé; sachant que parmis ces triplets, 271 millions ont un indice de confiance de 0,9 ou plus. Les données ne sont pas fiables à 100\% mais suffisamment pour être exploitées.

KV va se construire sur trois étapes. Tout d'abord l'extraction de source des ressources du web, que ce soit les données en langage naturel, les annotations humaines les données graphiques ou tabulaires, etc. Pour chaque triple extrait, l'extracteur va attribuer un score de confiance. Ensuite la base va prédire la probabilité d'existence d'un triple en se basant sur ses propres données (ou dans une base existante). Enfin, la base détermine la probabilité pour qu'un triple soit vrai en se basant sur les résultats des étapes précédentes.

Le potentiel de KV peut s'avérer être une source de données primordiales pour les systèmes de fact-checking futurs. Cette base est en revanche toujours à l'état de concept.
\\*
Pour résumer, l'idée derrière KV serait une base de connaissance capable de s'auto-alimenter et s'auto-valider avec des sources de données hétérogènes et récentes. Cela signifie que KV, en s'alimentant, serait capable de réaliser des opérations de fact-checking à grande échelle et sur un source aussi vaste que le web.

Un problème se pose tout de même, comment réagir si deux informations se contredisent sans qu'aucune règles définit dans les ontologies ne soit là pour trancher ? Dans un tel cas de figure, l'une des sources est forcément fausse. Le plus gros challenge reste donc d'assurer la fiabilité de la source.

\subsection{Fiabilité des sources}

Assurer la fiabilité d'une source sur le web permettrait de réduire la marge d'erreur lorsqu'un système utilise des sources web pour construire son argumentaire. De plus pour la construction de bases de connaissance cela permettrait de ne plus se fier qu'à ses données et son expérience pour assurer la validité d'un triple \cite{dong2015knowledge}.

Il existe un système de fact-checking qui mêle construction de base de connaissances automatique et analyse de la fiabilité des sources. Ce système est DeFacto \cite{gerber2015}. Contrairement aux autres systèmes, DeFacto est multilingue. Il va retourner un verdict sur la la validité d'une assertion (sous forme de triple) en lui apportant un score de fiabilité ainsi que des preuves (sources) vérifiée. DeFacto essaie aussi d'ajouter une dimension temporelle à l'analyse d'un fait. Certains faits ne sont vrais que dans un laps de temps déterminé.

Comme KV, DeFacto va tenter d'assurer la fiabilité des sources qu'il requête. Il utilise le machine learning à différents niveaux. Tout d'abord pour la détection et l'extraction de faits sous la forme de triple (plus précisément des faits en langage naturel qui ont la forme de triple) il utilise le framework Bootstrapping Linked Data (ré-entraîné). BOA est entraîné à la détection de triple dans plusieurs langues en se basant sur DBPedia. Outre les techniques de TALN pour la validation des faits et la recherche de source, DeFacto va tenter d'apposer un score de confiance sur les sources requêtées. Ce score de confiance se base sur différents indicateurs. La similarité entre le triple et les résultats trouvés (similarité avec les titres notamment, puis le contenu des pages). Cela permet d'évaluer l'apport qualitatif que peut avoir une source. Ensuite pour chaque source on va effectuer une recherche en se basant sur le titre et analyser les résultats retournés. Ici on tente de voir si plusieurs sources corroborent un fait (et ses sources potentielles). D'autres étapes vont analyser la similarité entre les sources pour un triple donné. Les sources sont analysées entre elles pour récupérer les points communs et ainsi assurer une meilleure fiabilité. Le TALN est au centre de cette démarche. D'autres approches comme celle de KV vont analyser les sources en essayant de réaliser des opérations de fact-checking en décomposant la source en triple et en analysant chacun de ces triples. La fiabilité de la source peut donc être évaluée en fonction de ce que la base sait déjà.

D'autres alternatives sont possibles et à évaluer, on peut par exemple déterminer le niveau de confiance d'une source en fonction des analyses précédentes. Ainsi au fur et à mesure il serait possible d'anticiper le niveau de confiance d'une source en fonction d'un score de confiance. La confiance sera plus grande si la source est le journal Le Monde (et non BuzzFeed). Autre possibilité, sachant que les sites de fake news sont souvent interconnectés, si l'on prend le plus gros site de fake news, il serait peut être possible de construire un graphe permettant de cartographier les sites potentiellement affiliés et ainsi éviter des sources néfastes pour le système.

\subsection{Machine learning et knowledge graph}

Le machine learning et les KGs peuvent s'associer de plusieurs manières différentes. Le machine learning peut s'appliquer sur les méthodes de traitement des KGs pour les améliorer. Ou alors les données complexes des KGs peuvent être utilisées pour entraîner des algorithmes de machine learning \cite{wilcke2017knowledge}. Il peut encore permettre la construction automatique de bases de connaissance.

Par exemple, le Statistical relationnal learning (SRL) aussi appelé relational machine learning permet la création de modèles statistiques pour des données relationnelles. La modélisation de la connaissance avec SRL va permettre de traiter l'incertitude liée à la création de nouvelles entités ou relations dans un graphe \cite{nickel2016review}. Cette méthode va permettre de calculer la probabilité qu'une nouvelle relation soit possible et pertinente entre deux entités. Typiquement, SRL peut être utilisé conjointement avec des méthodes de lecture automatique et d'extraction d'information pour construire automatiquement des bases de connaissance. Ici le machine learning peut être utilisé pour étendre des KGs existants en se basant sur leur structure et les données qu'ils contiennent.

KV utilise une approche semblable. Cette base peut potentiellement nous permettre d'avoir une source de données fiable et conséquente. En revanche il faut pouvoir utiliser efficacement cette source de données. Nous avons vu plusieurs techniques de fact-checking sur des KGs, mais appliqué sur une base comme KV, le temps de calcul peut être conséquent.

A première vu, le machine learning ne peut pas traiter d'informations complexes pour effectuer des tâches complexes (encore plus complexes). L'utilisation basique du machine learning revient à faire du bourrage de crâne et lui demander de faire une opération en se basant sur son expérience. Comment un système qui associerait le machine learning aux KGs pourrait-il permettre de justifier une assertion ? Dans le cas de vérification stricte d'un fait, on ne peut pas se baser sur son expérience passée. Même si le système a déjà évalué l'assertion suivante : \enquote{Joseph Boyden wrotes Three Day Road} cela ne lui fournira aucune information sur \enquote{Robin Hobb wrotes Assassin's Apprentice} pour définir si cette assertion est vraie ou fausse. En revanche, si on l'utilise pour traiter des KGs de façon plus sophistiqué, le système va pouvoir identifier le sujet et l'objet comme étant une personne et un livre et va pouvoir utiliser son expérience acquise sur une assertion précédente pour requêter le KG. Dans le cas des knowledge streams, par exemple, cela permet de passer outre la reconstruction du graphe à chaque requête (une fois le système bien entraîné).

Dans le cas du fact-checking, le machine learning peut difficilement être vu autrement que comme un outil pour améliorer les possibilitées liées aux KGs (ou à des étapes clés).

\subsection{Conclusion}

L'IA et le machine learning ont et auront un rôle important à jouer dans le processus de fact-checking. Ils sont omniprésents, que ce soit avec le TALN ou le machine learning. 

L'utilisation du machine learning doit se faire avec prudence. Les choses dans le monde sont en constante évolution, tout comme les données disponibles sur le web. Dans le cas d'une base de connaissance, la base doit pouvoir évoluer, même chose pour les algorithmes d'apprentissage. Si une nouvelle relation apparaît, il faut que notre système puisse la prendre en compte.

Le machine learning et les KGs sont au centre des processus de fact-checking. Si l'on veut créer un système le plus autonome possible, il est nécessaire d'étudier les meilleures façons de les coupler. Savoir comment l'un peut palier aux faiblesses de l'autre.